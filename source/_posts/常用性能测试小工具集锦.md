# 常用性能测试小工具集锦

## 性能测试

​	基于工作中做的性能测试，收纳整理出《常用性能测试小工具集锦》。主要从性能测试和工具集锦两个方面分享。

### 性能测试

​		性能测试是一种评估系统性能的方法，它可以检测系统的可扩展性、吞吐量、响应时间、负载能力、稳定性和安全性等指标。性能测试可以帮助开发人员、系统管理员和业务用户了解系统的实际运行情况，并找出可能存在的瓶颈和问题。

#### 性能测试指标

​		衡量系统性能的评价标准。

##### **系统性能测试指标**

​		响应时间、系统处理能力，吞吐量，并发用户数，错误率等。

##### 响应时间

​		简称RT，指的是客户发出请求到得到系统响应的整个过程的时间。也就是用户从客户端发起一个请求开始，到客户端接收到从服务器端返回的响应结束，整个过程所耗费的时间。

##### 系统处理能力

​		系统在利用系统硬件平台和软件平台进行信息处理的能力。系统处理能力通过系统每秒钟能够处理的交易数量来评价。交易有两种理解：一是业务人员角度的一笔业务过程；二是系统角度的一次交易申请和响应过程。前者称为业务交易过程，后者称为事务。系统处理能力又用HPS(每秒点击次数)，TPS(系统每秒处理交易次数)，QPS(系统每秒处理查询次数)指标来度量。

##### 吞吐量

​		吞吐量是指系统在单位时间内处理请求的数量。尤其对于并发系统，通常需要用吞吐量作为性能指标。

##### 并发用户数

​		并发用户数指在同一时刻内，登录系统并进行业务操作的用户数量。

##### 错误率

​		简称FR，指系统在负载情况下，失败交易的概率。错误率＝(失败交易数/交易总数)*100%。

#### **资源性能指标**

CPU、内存、磁盘吞吐量、网络吞吐量等。

##### CPU

​		CPU指标主要指的CPU利用率。单位时间内服务器CPU的使用统计，可以用除CPU空闲时间外其他时间占总CPU时间的百分比来表示。即：CPU使用率=1-CPU空闲时间/总CPU时间。

```
字段说明：
us (user)：用户态的CPU使用时间比例，是用户运行程序的真正时间，它不包括后面的ni时间。
sy (system): 内核态的CPU使用时间比例，是操作系统的运行时间，操作系统运行时，用户运行程序往往处于等待状态。
ni (nice): 表示低优先级用户态的CPU时间比例，取值范围为[-20,19]，数值越大，则优先级越低。
id (idle): 表示空闲的CPU时间比例，值越大，CPU空闲时间比例越高，利用率越低。
wa (iowait): 表示处于IO等待状态的CPU时间比例。
hi (hard interrupt): 表示处理硬中断的CPU时间比例。硬中断，也叫异步中断。硬中断是由硬件设备依照CPU时钟信号产生的，即意味着中断发生具备随机性和突发性，可以在指令正在执行时发生。
si (soft interrupt): 与hi相反，表示处理软中断的CPU时间比例。软中断，也叫同步中断。软中断是由CPU执行中断产生指令时产生，是由程序预先实现好的，不是随机的。
st (steal): 表示当前系统运行在虚拟机中被其他虚拟机占用的CPU时间比例。这体现为物理 CPU 没有办法为当前系统服务，通常正在为另一个系统服务。 在虚拟机超卖比较严重的场景，这个数值非常明显。 这部分时间显然不是当前系统所用，而是被其他系统占用了。
```

​		当us很高时，说明CPU时间主要消耗在用户代码上，可以从用户代码角度考虑优化性能；当sy很高时，说明CPU时间主要消耗在内核上，可以从是否系统调用频繁、CPU进程或线程切换频繁角度考虑性能的优化；当wa很高时，说明有进程在进行频繁的IO操作，可能是磁盘IO或者网络IO。一般情况下，如果%us+%sy<=70%，我们可以认为系统的运行状态良好。

##### 内存

​		total(内存总量),free(空闲内存),used(已使用内存),buffer/cache(缓存)。buffers与cached都是内存操作，用来保存系统曾经打开过的文件以及文件属性信息，这样当操作系统需要读取某些文件时，会优先从buffers与cached内存区查找，然后才从磁盘读取。通过缓存，能够大大提高了操作系统的性能。因此，对于linux系统来说，可用于分配的内存不止free的内存，同时还包括cached的内存（其实还包括buffers的内存）。cached和buffers都属于缓存，它们的区别主要在于cached主要用来缓冲频繁读取的文件，它可以直接记忆我们打开的文件内容；而buffers主要用来给块设备做的缓冲大小，只记录文件系统的元数据(metadata)以及缓存文件(tracking in-flight pages)信息，比如存储目录里面的内容，权限等。

在性能测试中，经常会用到系统已用内存、物理已用内存、系统内存占用率以及物理内存占用率这几个指标，它们的计算公式如下：

```
物理已用内存 = 实际已用内存 - 缓冲 - 缓存 
物理空闲内存 = 总物理内存 - 实际已用内存 + 缓冲 + 缓存 
应用程序可用空闲内存 = 总物理内存 - 实际已用内存 
应用程序已用内存 = 实际已用内存 - 缓冲 - 缓存
total = used + free + buffer/cache
avaiable = free + buffer/cache
```

​		一般情况下，系统内存占用率<=70%，我们可以认为系统的内存使用情况良好，如果超出则说明系统内存资源紧张。

##### 磁盘

- 磁盘I/O：I/O，即input/output，磁盘的输入输出，输入指的是对磁盘写入数据，输出指的是从磁盘读出数据，磁盘I/O可以理解为读写。应用发起的一次或多次数据请求，I/O请求的数据量又称I/O大小，单位为KiB，例如4KiB、256KiB、1024KiB等；
- 磁盘IOPS：磁盘IOPS是指一秒内磁盘进行多少次I/O读写；
- 磁盘吞吐量：每秒磁盘I/O的流量，即磁盘写入加上读出的数据的大小。

```
I/O 读写的类型，大体上可以分为：
读 / 写 I/O：存数据时候对应的是写操作，取数据的时候对应的是是读操作。
大 / 小块 I/O：这个数值指的是控制器指令中给出的连续读出扇区数目的多少。
连续 / 随机 I/O：连续 I/O 指的是本次 I/O 给出的初始扇区地址和上一次 I/O 的结束扇区地址是完全连续或者相隔不多的。反之，如果相差很大，则算作一次随机 I/O。连续 I/O 比随机 I/O 效率高，因为在做连续 I/O 的时候，磁头几乎不用换道，或者换道的时间很短；而对于随机 I/O，如果这个 I/O 很多的话，会导致磁头不停地换道，造成效率的极大降低。
顺序 / 并发 I/O：从概念上讲，并发 I/O 就是指向一块磁盘发出一条 I/O 指令后，不必等待它回应，接着向另外一块磁盘发 I/O 指令。对于具有条带性的 RAID（LUN），对其进行的 I/O 操作是并发的，例如：raid 0+1(1+0),raid5 等。反之则为顺序 I/O。
吞吐量 = IOPS * I/O大小
```

##### 网络

​	网络吞吐量是指在某个时刻，在网络中的两个节点之间，提给给网络应用的剩余带宽。 即在没有帧丢失的状况下，设备能够接受的最大速率。

```
通常是以 4 个指标来衡量网络的性能，分别是带宽、延时、吞吐率、PPS（Packet Per Second），它们表示的意义如下
带宽，表示链路的最大传输速率，单位是 b/s （比特 / 秒），带宽越大，其传输能力就越强。
延时，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。
吞吐率，表示单位时间内成功传输的数据量，单位是 b/s（比特 / 秒）或者 B/s（字节 / 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。
PPS，全称是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。
当然，除了以上这四种基本的指标，还有一些其他常用的性能指标，比如：

网络的可用性，表示网络能否正常通信；
并发连接数，表示 TCP 连接数量；
丢包率，表示所丢失数据包数量占所发送数据组的比率；
重传率，表示重传网络包的比例；
```

## 工具集锦

#### unixBench

UnixBench的测试能力包含系统调用、读写、进程、2D、3D、管道、运算等系统基准性能，会对系统CPU、内存、磁盘、网络等各个方面进行一系列的测试。

```
./Run -c 1 -c 8 //表示执行两次，第一次单个copies,第二次8个copies的测试任务。
```

测试结果

```
make all
make[1]: Entering directory '/home/wang/UOS/Uswift/test-tool/UnixBench5.1.3-1'
Checking distribution of files
./pgms  exists
./src  exists
./testdir  exists
./results  exists
make[1]: Leaving directory '/home/wang/UOS/Uswift/test-tool/UnixBench5.1.3-1'

   #    #  #    #  #  #    #          #####   ######  #    #   ####   #    #
   #    #  ##   #  #   #  #           #    #  #       ##   #  #    #  #    #
   #    #  # #  #  #    ##            #####   #####   # #  #  #       ######
   #    #  #  # #  #    ##            #    #  #       #  # #  #       #    #
   #    #  #   ##  #   #  #           #    #  #       #   ##  #    #  #    #
    ####   #    #  #  #    #          #####   ######  #    #   ####   #    #

   Version 5.1.3                      Based on the Byte Magazine Unix Benchmark

   Multi-CPU version                  Version 5 revisions by Ian Smith,
                                      Sunnyvale, CA, USA
   January 13, 2011                   johantheghost at yahoo period com


1 x Dhrystone 2 using register variables  1 2 3 4 5 6 7 8 9 10

1 x Double-Precision Whetstone  1 2 3 4 5 6 7 8 9 10

1 x Execl Throughput  1 2 3

1 x File Copy 1024 bufsize 2000 maxblocks  1 2 3

1 x File Copy 256 bufsize 500 maxblocks  1 2 3

1 x File Copy 4096 bufsize 8000 maxblocks  1 2 3

1 x Pipe Throughput  1 2 3 4 5 6 7 8 9 10

1 x Pipe-based Context Switching  1 2 3 4 5 6 7 8 9 10

1 x Process Creation  1 2 3

1 x System Call Overhead  1 2 3 4 5 6 7 8 9 10

1 x Shell Scripts (1 concurrent)  1 2 3

1 x Shell Scripts (8 concurrent)  1 2 3

8 x Dhrystone 2 using register variables  1 2 3 4 5 6 7 8 9 10

8 x Double-Precision Whetstone  1 2 3 4 5 6 7 8 9 10

8 x Execl Throughput  1 2 3

8 x File Copy 1024 bufsize 2000 maxblocks  1 2 3

8 x File Copy 256 bufsize 500 maxblocks  1 2 3

8 x File Copy 4096 bufsize 8000 maxblocks  1 2 3

8 x Pipe Throughput  1 2 3 4 5 6 7 8 9 10

8 x Pipe-based Context Switching  1 2 3 4 5 6 7 8 9 10

8 x Process Creation  1 2 3

8 x System Call Overhead  1 2 3 4 5 6 7 8 9 10

8 x Shell Scripts (1 concurrent)  1 2 3

8 x Shell Scripts (8 concurrent)  1 2 3

========================================================================
   BYTE UNIX Benchmarks (Version 5.1.3)

   System: wang-PC: GNU/Linux
   OS: GNU/Linux -- 5.15.77-amd64-desktop -- #2 SMP Thu Jun 15 16:06:18 CST 2023
   Machine: x86_64 (unknown)
   Language: en_US.utf8 (charmap="UTF-8", collate="UTF-8")
   CPU 0: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 1: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 2: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 3: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 4: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 5: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 6: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   CPU 7: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (4199.9 bogomips)
          Hyper-Threading, x86-64, MMX, Physical Address Ext, SYSENTER/SYSEXIT, SYSCALL/SYSRET, Intel virtualization
   14:50:41 up 11 days, 23:45,  1 user,  load average: 0.95, 1.32, 7.18; runlevel 5

------------------------------------------------------------------------
Benchmark Run: Wed Jan 24 2024 14:50:41 - 15:18:32
8 CPUs in system; running 1 parallel copy of tests

Dhrystone 2 using register variables       47877041.4 lps   (10.0 s, 7 samples)
Double-Precision Whetstone                     7784.4 MWIPS (9.0 s, 7 samples)
Execl Throughput                               5666.5 lps   (30.0 s, 2 samples)
File Copy 1024 bufsize 2000 maxblocks       1493924.1 KBps  (30.0 s, 2 samples)
File Copy 256 bufsize 500 maxblocks          426805.3 KBps  (30.0 s, 2 samples)
File Copy 4096 bufsize 8000 maxblocks       3119870.2 KBps  (30.0 s, 2 samples)
Pipe Throughput                             2577750.5 lps   (10.0 s, 7 samples)
Pipe-based Context Switching                 296557.3 lps   (10.0 s, 7 samples)
Process Creation                              13157.5 lps   (30.0 s, 2 samples)
Shell Scripts (1 concurrent)                  14761.5 lpm   (60.0 s, 2 samples)
Shell Scripts (8 concurrent)                   4321.8 lpm   (60.0 s, 2 samples)
System Call Overhead                        2784511.9 lps   (10.0 s, 7 samples)

System Benchmarks Index Values               BASELINE       RESULT    INDEX
Dhrystone 2 using register variables         116700.0   47877041.4   4102.6
Double-Precision Whetstone                       55.0       7784.4   1415.3
Execl Throughput                                 43.0       5666.5   1317.8
File Copy 1024 bufsize 2000 maxblocks          3960.0    1493924.1   3772.5
File Copy 256 bufsize 500 maxblocks            1655.0     426805.3   2578.9
File Copy 4096 bufsize 8000 maxblocks          5800.0    3119870.2   5379.1
Pipe Throughput                               12440.0    2577750.5   2072.1
Pipe-based Context Switching                   4000.0     296557.3    741.4
Process Creation                                126.0      13157.5   1044.2
Shell Scripts (1 concurrent)                     42.4      14761.5   3481.5
Shell Scripts (8 concurrent)                      6.0       4321.8   7203.0
System Call Overhead                          15000.0    2784511.9   1856.3
                                                                   ========
System Benchmarks Index Score                                        2360.4

------------------------------------------------------------------------
Benchmark Run: Wed Jan 24 2024 15:18:32 - 15:46:49
8 CPUs in system; running 8 parallel copies of tests

Dhrystone 2 using register variables      176274670.8 lps   (10.0 s, 7 samples)
Double-Precision Whetstone                    46994.6 MWIPS (9.4 s, 7 samples)
Execl Throughput                              20151.0 lps   (30.0 s, 2 samples)
File Copy 1024 bufsize 2000 maxblocks       1745833.5 KBps  (30.0 s, 2 samples)
File Copy 256 bufsize 500 maxblocks          478830.4 KBps  (30.0 s, 2 samples)
File Copy 4096 bufsize 8000 maxblocks       4568801.0 KBps  (30.0 s, 2 samples)
Pipe Throughput                             9157085.1 lps   (10.0 s, 7 samples)
Pipe-based Context Switching                1132991.1 lps   (10.0 s, 7 samples)
Process Creation                              44340.3 lps   (30.0 s, 2 samples)
Shell Scripts (1 concurrent)                  36537.4 lpm   (60.0 s, 2 samples)
Shell Scripts (8 concurrent)                   4653.2 lpm   (60.1 s, 2 samples)
System Call Overhead                        8498217.7 lps   (10.0 s, 7 samples)

System Benchmarks Index Values               BASELINE       RESULT    INDEX
Dhrystone 2 using register variables         116700.0  176274670.8  15104.9
Double-Precision Whetstone                       55.0      46994.6   8544.5
Execl Throughput                                 43.0      20151.0   4686.3
File Copy 1024 bufsize 2000 maxblocks          3960.0    1745833.5   4408.7
File Copy 256 bufsize 500 maxblocks            1655.0     478830.4   2893.2
File Copy 4096 bufsize 8000 maxblocks          5800.0    4568801.0   7877.2
Pipe Throughput                               12440.0    9157085.1   7361.0
Pipe-based Context Switching                   4000.0    1132991.1   2832.5
Process Creation                                126.0      44340.3   3519.1
Shell Scripts (1 concurrent)                     42.4      36537.4   8617.3
Shell Scripts (8 concurrent)                      6.0       4653.2   7755.3
System Call Overhead                          15000.0    8498217.7   5665.5
                                                                   ========
System Benchmarks Index Score                                        5874.3
```

测试项目

![image-20240124153054135](/home/wang/.config/Typora/typora-user-images/image-20240124153054135.png)

```
Dhrystone测试：
	测试聚焦在字符串处理，没有浮点运算操作。这个测试用于测试链接器编译、代码优化、内存缓存、等待状态、整数数据类型等。
Whetstone测试：
	测试项目用于测试浮点运算效率和速度。含若干个科学计算的典型性能模块，包含大量的C语言函数,sin cos sqrt exp和日志以及使用整数和浮点的数学操作。包含数组访问、条件分支和过程调用。
Execl Throughput测试：
	每秒钟可以执行的execl系统调用的次数。
File Copy测试：
	这项测试衡量文件数据从一个文件被传输到另外一个，使用大量的缓存。包括文件的读、写、复制测试，测试指标是一定时间内（默认是10秒）被重写、读、复制的字符数量。
Pipe Throughput(管道吞吐)测试:
	测试在一秒钟一个进程写512比特到一个管道中并且读回来的次数。管道吞吐测试和实际编程有差距。
Pipe-based Context Switching(基于管道的上下文交互)测试:
	测试衡量两个进程通过管道交换和整数倍的增加吞吐的次数。基于管道的上下文切换和真实程序很类似。测试程序产生一个双向管道通讯的子线程。
Process Creation(进程创建)测试:
	这项测试衡量一个进程能产生子线程并且立即退出的次数。新进程真的创建进程阻塞和内存占用，所以测试程序直接使用内存带宽。这项测试用于典型的比较大量的操作系统进程创建操作。
Shell Scripts测试:
	shell脚本测试用于衡量在一分钟内，一个进程可以启动并停止shell脚本的次数，通常会测试1，2， 3， 4， 8 个shell脚本的共同拷贝，shell脚本是一套转化数据文件的脚本。
System Call Overhead （系统调用消耗）测试:
	测试衡量进入和离开系统内核的消耗，例如，系统调用的消耗。程序简单重复的执行getpid调用（返回调用的进程id）。消耗的指标是调用进入和离开内核的执行时间。
Graphical Tests(图形)测试:
	测试非常粗的2D和3D图形性能，尤其是3D测试非常有限。测试结果和硬件，系统合适的驱动关系很大。
```

#### fio

fio主要用来测试硬盘io性能。这个工具的可定制性非常强，可以根据测试者的想法进行各种混合io测试，它支持13种不同类型io引擎（libaio、sync、mmap、posixaio、network等等）。它可以测试块设备或文件，可以通过多线程或进程模拟各种io操作，可以测试统计iops、带宽和时延等性能。我们主要使用fio工具进行存储性能测试。

```
fio -name=iouring_test -filename=/mnt/vdd/testfile -iodepth=128 -thread -rw=randread -ioengine=io_uring -sqthread_poll=1 -direct=1 -bs=4k -size=10G -numjobs=1 -runtime=120 -group_reporting
```

说明：
filename=/dev/sdb1    测试文件名称，通常选择需要测试的盘的data目录。
direct=1         测试过程绕过机器自带的buffer。使测试结果更真实。
bs=4k          单次io的块文件大小为16k
size=5g  本次的测试文件大小为5g，以每次4k的io进行测试。
numjobs=1        本次的测试线程为30.
runtime=120       测试时间为120秒，如果不写则一直将5g文件分4k每次写完为止。
ioengine=io_uring      io引擎使用io_uring方式
group_reporting     关于显示结果的，汇总每个进程的信息。

此外
rwmixwrite=30      在混合读写的模式下，写占30%
lockmem=1g        只使用1g内存进行测试。
zero_buffers       用0初始化系统buffer。
nrfiles=8        每个进程生成文件的数量。
read 顺序读
write 顺序写
rw,readwrite 顺序混合读写
randwrite 随机写
randread 随机读
randrw 随机混合读写

```
uring -sqthread_poll=1 -direct=1 -bs=4k -size=10G -numjobs=1 -runtime=120 -group_reporting
iouring_test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=io_uring, iodepth=128
fio-3.22
Starting 1 thread
Jobs: 1 (f=1): [r(1)][3.2%][eta 01h:01m:42s]                        
iouring_test: (groupid=0, jobs=1): err= 0: pid=63227: Wed Jan 24 15:55:58 2024
  read: IOPS=682, BW=2729KiB/s (2795kB/s)(330MiB/123713msec)  //读操作的iops(每秒输入输出量)和bw(带宽)
    clat (usec): min=506, max=11807k, avg=187540.47, stdev=846840.59
     lat (usec): min=507, max=11807k, avg=187541.31, stdev=846840.60
    clat percentiles (usec):
     |  1.00th=[    1188],  5.00th=[    5800], 10.00th=[    8160],
     | 20.00th=[   11469], 30.00th=[   15008], 40.00th=[   19792],
     | 50.00th=[   26084], 60.00th=[   36439], 70.00th=[   56361],
     | 80.00th=[  104334], 90.00th=[  238027], 95.00th=[  425722],
     | 99.00th=[ 5804917], 99.50th=[ 7214203], 99.90th=[ 8422163],
     | 99.95th=[ 8657044], 99.99th=[10804528]
   bw (  KiB/s): min= 1357, max= 5397, per=100.00%, avg=2806.35, stdev=636.20, samples=240
   iops        : min=  339, max= 1349, avg=701.40, stdev=159.08, samples=240
  lat (usec)   : 750=0.13%, 1000=0.50%
  lat (msec)   : 2=0.93%, 4=1.25%, 10=12.60%, 20=25.15%, 50=27.08%
  lat (msec)   : 100=11.79%, 250=11.16%, 500=5.21%, 750=1.25%, 1000=0.54%
  lat (msec)   : 2000=0.58%, >=2000=1.83%
  cpu          : usr=99.85%, sys=0.08%, ctx=94, majf=0, minf=0
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwts: total=84415,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=2729KiB/s (2795kB/s), 2729KiB/s-2729KiB/s (2795kB/s-2795kB/s), io=330MiB (346MB), run=123713-123713msec

Disk stats (read/write):
    dm-0: ios=84415/17, merge=0/0, ticks=15416332/27284, in_queue=15443616, util=100.00%, aggrios=84414/15, aggrmerge=1/2, aggrticks=15402295/25881, aggrin_queue=15260184, aggrutil=100.00%
  vda: ios=84414/15, merge=1/2, ticks=15402295/25881, in_queue=15260184, util=100.00%
```

#### lmbench

`Lmbench` 是一款简易可以移植的内存测试工具，其主要功能有，带宽测评（读取缓存文件、拷贝内存、读/写内存、管道、TCP），延时测评（上下文切换、网络、文件系统的建立和删除、进程创建、[信号处理](https://so.csdn.net/so/search?q=信号处理&spm=1001.2101.3001.7020)、上层系统调用、内存读入反应时间）等功能。

#### Stream

Stream内存带宽性能测试基准工具。

stream通过生成四种不同模式下的内存读写操作，用于测试内存带宽。

Copy操作最为简单，它先访问一个内存单元读出其中的值，再将值写入到另一个内存单元。

Scale操作先从内存单元读出其中的值，作一个乘法运算，再将结果写入到另一个内存单元。

Add操作先从内存单元读出两个值，做加法运算， 再将结果写入到另一个内存单元。

Triad的中文含义是将三个组合起来，在本测试中表示的意思是将Copy、Scale、Add三种操作组合起来进行测试。具体操作方式是：先从内存数组中读两个值a、b，对其进行乘加混合运算（a+因子* b），将运算结果写入到另一个内存单元。 

#### iozone

IOzone是文件系统性能测试工具。可以测试不同的操作系统中文件系统的读写性能。可以测试 Read, write, re-read,re-write, read backwards, read strided, fread, fwrite, random read, pread, mmap, aio_read, aio_write 等等不同的模式下的硬盘的性能。

| Write          | 测试向一个新文件写入的性能。当一个新文件被写入时，不仅仅是那些文件中的数据需要被存储，还包括那些用于定位数据存储在存储介质的具体位置的额外信息。这些额外信息被称作 “元数据”。它包括目录信息，所分配的空间和一些与该文件有关但又并非该文件所含数据的其他数据。拜这些额外信息所赐，Write 的性能通常会比 Re-write 的性能低。 |
| -------------- | ------------------------------------------------------------ |
| Re-write       | 测试向一个已存在的文件写入的性能。当一个已存在的文件被写入时，所需工作量较少，因为此时元数据已经存在。Re-write 的性能通常比 Write 的性能高。 |
| Read           | 测试读一个已存在的文件的性能。                               |
| Re-Read        | 测试读一个最近读过的文件的性能。Re-Read 性能会高些，因为操作系统通常会缓存最近读过的文件数据。这个缓存可以被用于读以提高性能。 |
| Random Read    | 测试读一个文件中的随机偏移量的性能。许多因素可能影响这种情况下的系统性能，例如：操作系统缓存的大小，磁盘数量，寻道延迟和其他。 |
| Random Write   | 测试写一个文件中的随机偏移量的性能。同样，许多因素可能影响这种情况下的系统性能，例如：操作系统缓存的大小，磁盘数量，寻道延迟和其他。 |
| Random Mix     | 测试读写一个文件中的随机偏移量的性能。同样，许多因素可能影响这种情况下的系统性能，例如：操作系统缓存的大小，磁盘数量，寻道延迟和其他。这个测试只有在吞吐量测试模式下才能进行。每个线程 / 进程运行读或写测试。这种分布式读 / 写测试是基于 round robin 模式的。最好使用多于一个线程 / 进程执行此测试。 |
| Backwards Read | 测试使用倒序读一个文件的性能。这种读文件方法可能看起来很可笑，事实上，有些应用确实这么干。MSC Nastran 是一个使用倒序读文件的应用程序的一个例子。它所读的文件都十分大（大小从 G 级别到 T 级别）。尽管许多操作系统使用一些特殊实现来优化顺序读文件的速度，很少有操作系统注意到并增强倒序读文件的性能。 |
| Record Rewrite | 测试写与覆盖写一个文件中的特定块的性能。这个块可能会发生一些很有趣的事。如果这个块足够小（比 CPU 数据缓存小），测出来的性能将会非常高。如果比 CPU 数据缓存大而比 TLB 小，测出来的是另一个阶段的性能。如果比此二者都大，但比操作系统缓存小，得到的性能又是一个阶段。若大到超过操作系统缓存，又是另一番结果。 |
| Strided Read   | 测试跳跃读一个文件的性能。举例如下：在 0 偏移量处读 4Kbytes，然后间隔 200Kbytes, 读 4Kbytes，再间隔 200Kbytes，如此反复。此时的模式是读 4Kbytes，间隔 200Kbytes 并重复这个模式。这又是一个典型的应用行为，文件中使用了数据结构并且访问这个数据结构的特定区域的应用程序常常这样做。许多操作系统并没注意到这种行为或者针对这种类型的访问做一些优化。同样，这种访问行为也可能导致一些有趣的性能异常。一个例子是在一个数据片化的文件系统里，应用程序的跳跃导致某一个特定的磁盘成为性能瓶颈。 |
| Fwrite         | 测试调用库函数 fwrite () 来写文件的性能。这是一个执行缓存与阻塞写操作的库例程。缓存在用户空间之内。如果一个应用程序想要写很小的传输块，fwrite () 函数中的缓存与阻塞 I/O 功能能通过减少实际操作系统调用并在操作系统调用时增加传输块的大小来增强应用程序的性能。这个测试是写一个新文件，所以元数据的写入也是要的。 |
| Frewrite       | 测试调用库函数 fwrite () 来写文件的性能。这是一个执行缓存与阻塞写操作的库例程。缓存在用户空间之内。如果一个应用程序想要写很小的传输块，fwrite () 函数中的缓存与阻塞 I/O 功能能通过减少实际操作系统调用并在操作系统调用时增加传输块的大小来增强应用程序的性能。 |

#### iperf3

iperf3是基于Client/Server的网络性能测试工具，通常用于测试网络上可达到的最大带宽，它能够测试TCP、UDP及SCTP的带宽质量，可以提供网络吞吐量、网络波动、网络丢包率以及最大传输单元大小等信息，能够帮助我们测试网络性能，定位网络瓶颈。

#### netperf

Netperf是一种网络性能的测量工具，可以测试基于TCP或UDP吞吐、响应速率。Netperf包括Clien和Server端，Server端主要用来实现监听工作，Client端进行测试。

#### ltp

LTP测试套件是测试Linux内核和内核相关特性的工具的集合。该工具的目的是通过把测试自动化引入到Linux内核测试，提高Linux的内核质量。通过功能测试、压力测试和回归测试来验证 Linux 系统的可靠性、稳定性和健壮性。整个项目约4000个测试用例。
